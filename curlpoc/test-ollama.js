// Quick test script to verify Ollama is working
async function testOllama() {
  console.log('üß™ Testing Ollama connection...\n')

  try {
    // Check if Ollama is running
    const tagsResponse = await fetch('http://localhost:11434/api/tags')
    if (!tagsResponse.ok) {
      throw new Error('Ollama not running')
    }
    console.log('‚úÖ Ollama is running')

    const tags = await tagsResponse.json()
    console.log(`üì¶ Available models: ${tags.models.map(m => m.name).join(', ')}\n`)

    // Test generation
    console.log('ü§ñ Testing cURL generation...\n')
    const response = await fetch('http://localhost:11434/api/generate', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: 'llama3.2',
        prompt: `You are a cURL command generator. Convert this request to a cURL command. Output ONLY the cURL command.

User request: "POST request to https://api.example.com/users with JSON data name: John, email: john@example.com"

cURL command:`,
        stream: false,
        options: {
          temperature: 0.3,
          num_predict: 150
        }
      })
    })

    const data = await response.json()
    console.log('Generated cURL command:')
    console.log('---')
    console.log(data.response.trim())
    console.log('---\n')
    console.log('‚úÖ Test successful!')

  } catch (error) {
    console.error('‚ùå Error:', error.message)
    console.log('\nüí° Make sure Ollama is installed and running:')
    console.log('   1. Install: https://ollama.ai')
    console.log('   2. Run: ollama run llama3.2')
  }
}

testOllama()
